#!/usr/bin/env python3
"""
üéØ MAIN APPLICATION - The Ultimate AI Video Tracking System
===========================================================

üöÄ FEATURES:
‚úÖ Real-time face detection and tracking with unique IDs
‚úÖ 30-second alert system when faces leave camera view
‚úÖ Dynamic engagement and attention scoring (real-time)
‚úÖ Comprehensive parameter analysis with mathematical formulas
‚úÖ High-performance optimized for 30+ FPS
‚úÖ Color-coded tracking boxes (green ‚Üí red when locked)
‚úÖ Live parameter overlays with highest accuracy
‚úÖ Automatic checkpoint saving and RL training

üéÆ CONTROLS:
- Press 'q' to quit
- Press 'r' to reset tracking
- Press 's' to save current state

üìä PERFORMANCE TARGETS:
- 30+ FPS real-time processing
- ‚â•98% attendance accuracy vs manual audit
- ‚â•70% precision on disengagement alerts
- <5s latency from event to dashboard

üîß This is the MAIN APPLICATION - Use this instead of run_app.py
"""

import os
import sys
import cv2
import numpy as np
import time
import gc
import platform
from pathlib import Path

# Disable TensorBoard warnings and other verbose outputs
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['OPENCV_LOG_LEVEL'] = 'ERROR'

def check_system_compatibility():
    """Check system compatibility and requirements"""
    print("üîç Checking system compatibility...")

    # Check Python version
    python_version = sys.version_info
    if python_version.major < 3 or (python_version.major == 3 and python_version.minor < 8):
        print(f"‚ùå Python 3.8+ required. Current: {python_version.major}.{python_version.minor}")
        return False
    print(f"‚úÖ Python {python_version.major}.{python_version.minor}.{python_version.micro}")

    # Check operating system
    system = platform.system()
    print(f"‚úÖ Operating System: {system}")

    # Check critical imports
    try:
        import torch
        print(f"‚úÖ PyTorch {torch.__version__}")
        if torch.cuda.is_available():
            print(f"‚úÖ CUDA available - {torch.cuda.device_count()} GPU(s)")
        else:
            print("‚ÑπÔ∏è  CUDA not available - using CPU")
    except ImportError:
        print("‚ùå PyTorch not installed. Run: python install.py")
        return False

    try:
        import mediapipe
        print("‚úÖ MediaPipe available")
    except ImportError:
        print("‚ùå MediaPipe not installed. Run: python install.py")
        return False

    try:
        import face_recognition
        print("‚úÖ Face Recognition available")
    except ImportError:
        print("‚ùå Face Recognition not installed. Run: python install.py")
        return False

    # Check camera availability
    try:
        cap = cv2.VideoCapture(0)
        if cap.isOpened():
            ret, frame = cap.read()
            if ret:
                print("‚úÖ Camera available")
                cap.release()
            else:
                print("‚ö†Ô∏è  Camera detected but cannot read frames")
                cap.release()
        else:
            print("‚ö†Ô∏è  No camera detected - you may need to connect a camera")
    except Exception as e:
        print(f"‚ö†Ô∏è  Camera test failed: {e}")

    # Create necessary directories
    directories = ['checkpoints', 'logs', 'exports']
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
    print("‚úÖ Required directories created")

    return True

# Import with fallbacks
try:
    import torch
    from loguru import logger
except ImportError as e:
    print(f"‚ùå Critical import failed: {e}")
    print("üîß Please run: python install.py")
    sys.exit(1)

def main():
    """Start the main AI video tracking application."""
    print("üéØ STARTING MAIN AI VIDEO TRACKING APPLICATION")
    print("=" * 70)
    print("üöÄ This is the PRIMARY application with all features!")
    print("‚úÖ 30-second alerts, real-time scoring, face tracking")
    print("=" * 70)

    # Check system compatibility first
    if not check_system_compatibility():
        print("\n‚ùå System compatibility check failed!")
        print("üîß Please install missing dependencies with: python install.py")
        input("Press Enter to exit...")
        return 1

    print("‚úÖ System compatibility check passed!")
    print("=" * 70)

    try:
        # Import enhanced tracking components
        print("Loading enhanced tracking components...")
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

        from utils.enhanced_tracking_overlay import EnhancedTrackingOverlay
        from utils.comprehensive_analyzer import ComprehensiveAnalyzer
        from utils.automatic_cleanup import AutomaticCleanupManager
        from utils.checkpoint_manager import CheckpointManager

        # Import RL components
        try:
            from models.reinforcement_learning import RLAgent
            RL_AVAILABLE = True
            print("‚úÖ RL components found and imported")
        except ImportError as e:
            print(f"‚ö†Ô∏è  RL components not available: {e}")
            print("Creating dummy RL classes...")
            class RLAgent:
                def __init__(self, *args, **kwargs):
                    self.episode = 0
                    self.step_count = 0
                    self.best_accuracy = 0.0
                    self.total_reward = 0.0
                def update_online(self, feedback):
                    self.step_count += 1
                    self.total_reward += feedback.get('total_reward', 0.0)
                    return 0.5
                def save_checkpoint(self, path):
                    pass
                def get_stats(self):
                    return {
                        'episode': self.episode,
                        'step_count': self.step_count,
                        'best_accuracy': self.best_accuracy,
                        'total_reward': self.total_reward
                    }
            RL_AVAILABLE = False
        
        print("‚úÖ Enhanced tracking components loaded")
        
        # Initialize components
        tracking_overlay = EnhancedTrackingOverlay()
        comprehensive_analyzer = ComprehensiveAnalyzer({})
        cleanup_manager = AutomaticCleanupManager()
        checkpoint_manager = CheckpointManager(checkpoint_dir="checkpoints")

        print("‚úÖ Components initialized")

        # Initialize RL Training System
        rl_trainer = None
        rl_active = False
        if RL_AVAILABLE:
            try:
                print("ü§ñ Initializing RL Training System...")
                rl_trainer = RLAgent(
                    algorithm="PPO",
                    config=None,
                    checkpoint_manager=checkpoint_manager
                )
                rl_active = True
                print("‚úÖ RL Training System initialized and ACTIVE")
            except Exception as e:
                print(f"‚ö†Ô∏è  RL initialization failed: {e}")
                rl_trainer = RLAgent()  # Use dummy
                rl_active = False
        else:
            print("‚ÑπÔ∏è  RL Training disabled - using dummy trainer")
            rl_trainer = RLAgent()  # Use dummy
        
        # Try to load AI models (with fallbacks)
        models = {}
        
        try:
            from models.face_detection import StateOfTheArtFaceDetector
            models['face_detector'] = StateOfTheArtFaceDetector(ensemble_mode='speed')
            print("‚úÖ Face detector loaded")
        except Exception as e:
            print(f"‚ö†Ô∏è  Face detector not available: {e}")
            models['face_detector'] = None

        try:
            from models.face_recognition import StateOfTheArtFaceRecognizer
            models['face_recognizer'] = StateOfTheArtFaceRecognizer()
            print("‚úÖ Face recognizer loaded")
        except Exception as e:
            print(f"‚ö†Ô∏è  Face recognizer not available: {e}")
            models['face_recognizer'] = None
        
        # Start video capture
        print("\nüé• Starting video capture...")
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            print("‚ùå Could not open camera")
            return 1
        
        print("‚úÖ Camera opened successfully")
        print("\nüöÄ ENHANCED TRACKING SYSTEM RUNNING!")
        print("Press 'q' to quit, 'r' to reset tracking")
        print("=" * 60)
        
        # Main processing loop with RL training
        frame_count = 0
        fps_counter = time.time()
        fps = 0

        # RL Training variables
        rl_episode = 0
        rl_step_count = 0
        rl_last_checkpoint = time.time()
        rl_checkpoint_interval = 300  # Save every 5 minutes
        rl_best_accuracy = 0.0

        print(f"ü§ñ RL Training: {'ACTIVE' if rl_active else 'DISABLED'}")

        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ùå Failed to read frame")
                break

            frame_count += 1

            # Face detection logic: run detection when needed
            detections = []

            # Always try to detect faces for tracking updates
            try:
                # Use OpenCV Haar Cascade for reliable face detection
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                faces = face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(50, 50))

                for (x, y, w, h) in faces:
                    detections.append({
                        'bbox': [int(x), int(y), int(x + w), int(y + h)],
                        'confidence': 0.85
                    })

                # Only print when detection mode is active
                if tracking_overlay.detection_active and detections:
                    print(f"üéØ Detected {len(detections)} face(s) - switching to tracking mode")

            except Exception as e:
                logger.error(f"Face detection error: {e}")
                # Fallback: try to use MediaPipe if available
                try:
                    import mediapipe as mp
                    mp_face_detection = mp.solutions.face_detection
                    mp_drawing = mp.solutions.drawing_utils

                    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:
                        results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

                        if results.detections:
                            h, w, _ = frame.shape
                            for detection in results.detections:
                                bbox = detection.location_data.relative_bounding_box
                                x = int(bbox.xmin * w)
                                y = int(bbox.ymin * h)
                                width = int(bbox.width * w)
                                height = int(bbox.height * h)

                                detections.append({
                                    'bbox': [x, y, x + width, y + height],
                                    'confidence': detection.score[0]
                                })
                except:
                    pass  # MediaPipe not available

            # Real-time analysis results (will be calculated by tracking overlay)
            analysis_results = {
                'timestamp': time.time(),
                'frame_number': frame_count
            }
            
            # Update tracking system
            tracking_overlay.update_tracking(detections, analysis_results)

            # RL TRAINING STEP - Perform reinforcement learning
            if rl_active and rl_trainer and frame_count % 5 == 0:  # Train every 5 frames
                try:
                    # Calculate reward based on tracking performance
                    tracking_stats = tracking_overlay.get_tracking_stats()

                    # Reward calculation based on multiple factors
                    detection_reward = len(detections) * 0.1  # Reward for detecting faces
                    tracking_reward = tracking_stats['tracked_objects'] * 0.2  # Reward for tracking
                    engagement_reward = analysis_results.get('engagement_score', 0.5) * 0.3
                    attention_reward = analysis_results.get('attention_level', 0.5) * 0.3

                    total_reward = detection_reward + tracking_reward + engagement_reward + attention_reward

                    # Perform RL step
                    feedback = {
                        'detection_count': len(detections),
                        'tracking_objects': tracking_stats['tracked_objects'],
                        'engagement_score': analysis_results.get('engagement_score', 0.5),
                        'attention_level': analysis_results.get('attention_level', 0.5),
                        'total_reward': total_reward,
                        'frame_quality': 1.0 if len(detections) > 0 else 0.5
                    }
                    rl_result = rl_trainer.update_online(feedback)
                    rl_step_count += 1

                    # Episode completion every 100 steps
                    if rl_step_count % 100 == 0:
                        rl_episode += 1
                        current_accuracy = min(1.0, total_reward / 4.0)  # Normalize to 0-1

                        # Save checkpoint if improved
                        if current_accuracy > rl_best_accuracy:
                            rl_best_accuracy = current_accuracy
                            checkpoint_manager.save_checkpoint({
                                'rl_trainer': rl_trainer,
                                'episode': rl_episode,
                                'accuracy': rl_best_accuracy,
                                'step_count': rl_step_count
                            }, f"rl_best_{rl_best_accuracy:.3f}")
                            print(f"üéØ New best RL accuracy: {rl_best_accuracy:.3f}")

                        # Regular checkpoint save
                        if rl_episode % 25 == 0:
                            checkpoint_manager.save_checkpoint({
                                'rl_trainer': rl_trainer,
                                'episode': rl_episode,
                                'accuracy': current_accuracy,
                                'step_count': rl_step_count
                            }, f"rl_episode_{rl_episode}")
                            print(f"üöÄ RL Episode {rl_episode} completed - Accuracy: {current_accuracy:.3f}")

                except Exception as e:
                    print(f"‚ö†Ô∏è  RL training step failed: {e}")

            # Create enhanced display
            display_frame = tracking_overlay.draw_tracking_overlay(frame, fps)
            
            # Add system info
            h, w = display_frame.shape[:2]
            
            # Performance info (top right) with RL status
            tracking_stats = tracking_overlay.get_tracking_stats()
            info_texts = [
                f"FPS: {fps:.1f}",
                f"Frame: {frame_count}",
                f"Mode: {'Detection' if tracking_overlay.detection_active else 'Tracking'}",
                f"Tracked: {tracking_stats['tracked_objects']}",
                f"Alerts: {tracking_stats['active_alerts']}",
                f"RL: {'ON' if rl_active else 'OFF'}"
            ]

            # Add RL specific info if active
            if rl_active and rl_trainer:
                try:
                    rl_stats = rl_trainer.get_stats()
                    info_texts.extend([
                        f"Episode: {rl_stats.get('episode', rl_episode)}",
                        f"Steps: {rl_stats.get('step_count', rl_step_count)}",
                        f"Best: {rl_stats.get('best_accuracy', rl_best_accuracy):.3f}"
                    ])
                except:
                    info_texts.extend([
                        f"Episode: {rl_episode}",
                        f"Steps: {rl_step_count}",
                        f"Best: {rl_best_accuracy:.3f}"
                    ])

            for i, text in enumerate(info_texts):
                pos = (w - 280, 30 + (i * 25))
                cv2.rectangle(display_frame, (pos[0] - 2, pos[1] - 20),
                             (pos[0] + 250, pos[1] + 5), (0, 0, 0), -1)
                cv2.putText(display_frame, text, pos, cv2.FONT_HERSHEY_SIMPLEX,
                           0.6, (255, 255, 255), 1)
            
            # Show frame
            cv2.imshow("Enhanced Tracking System", display_frame)
            
            # Calculate FPS
            if frame_count % 10 == 0:
                current_time = time.time()
                fps = 10 / (current_time - fps_counter)
                fps_counter = current_time
            
            # Handle key presses
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('r'):
                # Reset tracking
                tracking_overlay = EnhancedTrackingOverlay()
                print("üîÑ Tracking reset - detection mode re-enabled")
            elif key == ord('d'):
                # Toggle detection mode
                tracking_overlay.detection_active = not tracking_overlay.detection_active
                print(f"üîÑ Detection mode: {'ON' if tracking_overlay.detection_active else 'OFF'}")
            
            # Memory management
            if frame_count % 100 == 0:
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        # Save final RL checkpoint before cleanup
        if rl_active and rl_trainer:
            try:
                print("üíæ Saving final RL checkpoint...")
                checkpoint_manager.save_checkpoint({
                    'rl_trainer': rl_trainer,
                    'episode': rl_episode,
                    'accuracy': rl_best_accuracy,
                    'step_count': rl_step_count,
                    'final_save': True
                }, f"rl_final_{int(time.time())}")
                print(f"‚úÖ Final RL checkpoint saved - Episode: {rl_episode}, Best Accuracy: {rl_best_accuracy:.3f}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Failed to save final RL checkpoint: {e}")

        # Cleanup
        cap.release()
        cv2.destroyAllWindows()

        print("\n‚úÖ Enhanced tracking system with RL training stopped successfully")
        return 0
        
    except Exception as e:
        print(f"‚ùå Error starting enhanced tracking system: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
